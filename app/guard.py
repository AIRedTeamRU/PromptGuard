# app/guard.py
import re
import unicodedata
import joblib
from pathlib import Path

# ==============================
# 1. –ü–£–¢–ò –ö –ú–û–î–ï–õ–Ø–ú
# ==============================

BASE_DIR = Path(__file__).parent
VECTORIZER_PATH = BASE_DIR / "tfidf_vectorizer.pkl"
CLASSIFIER_PATH = BASE_DIR / "jailbreak_classifier.pkl"

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤
if not VECTORIZER_PATH.exists() or not CLASSIFIER_PATH.exists():
    raise FileNotFoundError(
        f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏! –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ {VECTORIZER_PATH} –∏ {CLASSIFIER_PATH} –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ø–∞–ø–∫–µ 'app'."
    )

vectorizer = joblib.load(VECTORIZER_PATH)
classifier = joblib.load(CLASSIFIER_PATH)

# ==============================
# 2. –°–ü–ò–°–ö–ò –£–ì–†–û–ó
# ==============================

# –¢–æ–∫—Å–∏—á–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
TOXIC_KEYWORDS = [
    "–æ—Å–∫–æ—Ä–±", "–æ–±–∏–¥", "–¥—É—Ä–∞–∫", "–∏–¥–∏–æ—Ç", "—É—Ä–æ–¥", "–≥–∞–¥", "–º–µ—Ä–∑–∞–≤–µ—Ü", "—Å–≤–æ–ª–æ—á—å",
    "–Ω–µ–Ω–∞–≤–∏—Å—Ç—å", "—Ä–∞—Å–∏–∑–º", "–∫—Å–µ–Ω–æ—Ñ–æ–±–∏—è", "–≥–æ–º–æ—Ñ–æ–±–∏—è", "—É–±–µ–π", "—Å–º–µ—Ä—Ç—å", "–Ω–∞—Å–∏–ª—å"
]

# –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–ü–î–Ω)
PDI_KEYWORDS = [
    "–∏–Ω–Ω", "—Å–Ω–∏–ª—Å", "–ø–∞—Å–ø–æ—Ä—Ç", "–Ω–æ–º–µ—Ä –∫–∞—Ä—Ç—ã", "cvv", "cvc", "–¥–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è",
    "–∞–¥—Ä–µ—Å –ø—Ä–æ–∂–∏–≤–∞–Ω–∏—è", "—Ç–µ–ª–µ—Ñ–æ–Ω", "email", "–ø–æ—á—Ç–∞", "–ª–æ–≥–∏–Ω", "–ø–∞—Ä–æ–ª—å"
]

# –ó–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Ç–µ–º—ã
BANNED_TOPICS = {
    "violence": ["–æ—Ä—É–∂–∏–µ", "–≤–∑—Ä—ã–≤", "—É–±–∏–π—Å—Ç–≤–æ", "–Ω–∞—Å–∏–ª–∏–µ"],
    "drugs": ["–Ω–∞—Ä–∫–æ—Ç–∏–∫–∏", "–º–∞—Ä–∏—Ö—É–∞–Ω–∞", "–∫–æ–∫–∞–∏–Ω"],
    "illegal": ["–≤–∑–ª–æ–º", "–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ", "–∫–∏–±–µ—Ä–ø—Ä–µ—Å—Ç—É–ø–Ω–æ—Å—Ç—å", "—Ñishing", "—Ñ–∏—à–∏–Ω–≥"]
}

# ==============================
# 3. –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ==============================

def normalize_unicode(text: str) -> str:
    return ''.join(
        c for c in unicodedata.normalize('NFD', text)
        if unicodedata.category(c) != 'So' and not unicodedata.combining(c)
    )

def leet_to_text(text: str) -> str:
    leet_map = {
        '0': '–æ', '1': '–∏', '2': '–∑', '3': '–µ', '4': '–∞', '5': '—Å',
        '6': '–±', '7': '—Ç', '8': '–≤', '9': '–¥',
        '@': '–∞', '$': '—Å', '!': '–∏', 'l': '–∏', '|': '–∏',
        'z': '–∑', 's': '—Å', 'g': '–¥', 'b': '–±'
    }
    text = text.lower()
    for leet, char in leet_map.items():
        text = text.replace(leet, char)
    return text

def clean_text(text: str) -> str:
    text = normalize_unicode(text)
    text = leet_to_text(text)
    text = re.sub(r'[^–∞-—è—ëa-z\s]', ' ', text, flags=re.IGNORECASE)
    return ' '.join(text.split()).lower()

def contains_word(text: str, word: str) -> bool:
    return bool(re.search(rf'\b{re.escape(word)}\b', text, re.IGNORECASE))

# ==============================
# 4. –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ==============================

def detect_jailbreak(prompt: str) -> dict:
    cleaned = clean_text(prompt)

    # üî• 1. –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ regex (jailbreak)
    jailbreak_patterns = [
        r'\b(ignore\s+(all\s+)?(previous\s+)?instructions?)\b',
        r'\b(developer\s+mode|—Ä–µ–∂–∏–º\s+—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞)\b',
        r'\b(DAN|Do\s+Anything\s+Now)\b',
        r'\b(–Ω–∞—Ä—É—à–∏\s+–ø—Ä–∞–≤–∏–ª–∞|–æ–±–æ–π–¥–∏\s+—Ñ–∏–ª—å—Ç—Ä)\b',
    ]
    for pattern in jailbreak_patterns:
        if re.search(pattern, cleaned, re.IGNORECASE):
            return {
                "flagged": True,
                "reason": "jailbreak_regex",
                "risk_score": 0.95,
                "suggested_rewrite": "–Ø –Ω–µ –º–æ–≥—É –≤—ã–ø–æ–ª–Ω–∏—Ç—å —ç—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å."
            }

    # ‚ò†Ô∏è 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏
    toxic_count = sum(1 for w in TOXIC_KEYWORDS if contains_word(cleaned, w))
    if toxic_count >= 1:
        risk = min(0.7 + toxic_count * 0.1, 0.9)
        return {
            "flagged": True,
            "reason": "toxic_content",
            "risk_score": round(risk, 2),
            "suggested_rewrite": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—â–∞–π—Ç–µ—Å—å —É–≤–∞–∂–∏—Ç–µ–ª—å–Ω–æ."
        }

    # üïµÔ∏è 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Ç–µ—á–∫–∏ –ü–î–Ω
    pdi_count = sum(1 for w in PDI_KEYWORDS if contains_word(cleaned, w))
    if pdi_count >= 1:
        return {
            "flagged": True,
            "reason": "pdi_leak",
            "risk_score": 0.9,
            "suggested_rewrite": "–ó–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ. –û–Ω –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –≤ —Ü–µ–ª—è—Ö –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏."
        }

    # üö´ 4. –ó–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Ç–µ–º—ã
    for category, words in BANNED_TOPICS.items():
        if any(contains_word(cleaned, w) for w in words):
            risk = 0.85 if category in ["violence", "drugs"] else 0.75
            return {
                "flagged": True,
                "reason": f"harmful_content_{category}",
                "risk_score": risk,
                "suggested_rewrite": "–≠—Ç–∞ —Ç–µ–º–∞ –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ —Ä–∞–º–∫–∏ –º–æ–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π."
            }

    # üìä 5. TF-IDF + –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö jailbreak-–∞—Ç–∞–∫)
    try:
        X = vectorizer.transform([cleaned])
        prob = classifier.predict_proba(X)[0][1]
        if prob > 0.85:  # –ø–æ–≤—ã—à–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
            return {
                "flagged": True,
                "reason": "jailbreak_tfidf",
                "risk_score": round(float(prob), 2),
                "suggested_rewrite": "–ó–∞–ø—Ä–æ—Å –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω —Å–∏—Å—Ç–µ–º–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏."
            }
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ ML-–º–æ–¥–µ–ª–∏: {e}")
        pass

    # ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–æ
    return {
        "flagged": False,
        "reason": "safe",
        "risk_score": 0.0,
        "suggested_rewrite": prompt
    }
