# app/guard.py
import re
import string
import unicodedata

# ==============================
# 1. –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê
# ==============================

def normalize_unicode(text: str) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —ç–º–æ–¥–∑–∏ –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –≤ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç (—á–∞—Å—Ç–∏—á–Ω–æ)"""
    # –£–¥–∞–ª—è–µ–º —ç–º–æ–¥–∑–∏ –∏ –Ω–µ–≤–∏–¥–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã
    return ''.join(
        c for c in unicodedata.normalize('NFD', text)
        if unicodedata.category(c) != 'So' and not unicodedata.combining(c)
    )

def leet_to_text(text: str) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –ø—Ä–æ—Å—Ç–æ–π leet-—è–∑—ã–∫ –≤ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç"""
    leet_map = {
        '0': '–æ', '1': '–∏', '2': '–∑', '3': '–µ', '4': '–∞', '5': '—Å',
        '6': '–±', '7': '—Ç', '8': '–≤', '9': '–¥',
        '@': '–∞', '$': '—Å', '!': '–∏', 'l': '–∏', '|': '–∏',
        'z': '–∑', 's': '—Å', 'g': '–¥', 'b': '–±'
    }
    text = text.lower()
    for leet, char in leet_map.items():
        text = text.replace(leet, char)
    return text

def clean_text(text: str) -> str:
    """–ü–æ–ª–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: —ç–º–æ–¥–∑–∏ ‚Üí —É–¥–∞–ª–µ–Ω–∏–µ, leet ‚Üí –±—É–∫–≤—ã, –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è ‚Üí –ø—Ä–æ–±–µ–ª—ã"""
    text = normalize_unicode(text)
    text = leet_to_text(text)
    # –ó–∞–º–µ–Ω—è–µ–º –≤—Å—ë, –∫—Ä–æ–º–µ –±—É–∫–≤ –∏ –ø—Ä–æ–±–µ–ª–æ–≤, –Ω–∞ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'[^–∞-—è—ëa-z\s]', ' ', text, flags=re.IGNORECASE)
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    return ' '.join(text.split()).lower()

# ==============================
# 2. –†–ê–°–®–ò–†–ï–ù–ù–´–ï –°–ü–ò–°–ö–ò –£–ì–†–û–ó
# ==============================

JAILBREAK_PATTERNS = [
    r'\b(act\s+as|pretend\s+to\s+be|simulate\s+as)\b',
    r'\b(developer\s+mode|—Ä–µ–∂–∏–º\s+—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞)\b',
    r'\b(ignore\s+(all\s+)?(previous\s+)?instructions?)\b',
    r'\b(bypass|override|circumvent)\s+(rules|restrictions|guidelines|filters)\b',
    r'\b(DAN|Do\s+Anything\s+Now|DAN\s+mode)\b',
    r'\b(–Ω–µ\s+—Å–æ–±–ª—é–¥–∞–π|–Ω–∞—Ä—É—à–∏)\s+(–ø—Ä–∞–≤–∏–ª–∞|–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏)\b',
]

# –¢–æ–∫—Å–∏—á–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç: –∞–≥—Ä–µ—Å—Å–∏—è, –Ω–µ–Ω–∞–≤–∏—Å—Ç—å, –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è
TOXIC_KEYWORDS = [
    "—Ç–æ–∫—Å–∏—á–Ω—ã–π", "toxic", "–Ω–µ–Ω–∞–≤–∏—Å—Ç—å", "hate", "—Ä–∞—Å–∏–∑–º", "racism",
    "–∫—Å–µ–Ω–æ—Ñ–æ–±–∏—è", "xenophobia", "–≥–æ–º–æ—Ñ–æ–±–∏—è", "homophobia",
    "–æ—Å–∫–æ—Ä–±", "–æ–±–∏–¥", "–Ω–µ–Ω–∞–≤–∏–¥", "—É–±–µ–π", "—Å–º–µ—Ä—Ç—å", "die", "kill",
    "–¥—É—Ä–∞–∫", "–∏–¥–∏–æ—Ç", "—É—Ä–æ–¥", "–≥–∞–¥", "–º–µ—Ä–∑–∞–≤–µ—Ü", "—Å–≤–æ–ª–æ—á—å"
]

# –ó–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Ç–µ–º—ã
BANNED_TOPICS = {
    "violence": ["–æ—Ä—É–∂–∏–µ", "weapon", "–≤–∑—Ä—ã–≤", "bomb", "—É–±–∏–π—Å—Ç–≤–æ", "murder", "–Ω–∞—Å–∏–ª–∏–µ", "violence"],
    "drugs": ["–Ω–∞—Ä–∫–æ—Ç–∏–∫–∏", "drugs", "–º–∞—Ä–∏—Ö—É–∞–Ω–∞", "cannabis", "–∫–æ–∫–∞–∏–Ω", "cocaine"],
    "self_harm": ["—Å–∞–º–æ—É–±–∏–π—Å—Ç–≤–æ", "suicide", "—Å—É–∏—Ü–∏–¥", "self-harm", "–∂–∏–∑–Ω—å –Ω–µ —Å—Ç–æ–∏—Ç"],
    "illegal": ["–≤–∑–ª–æ–º", "hack", "–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ", "fraud", "–∫–∏–±–µ—Ä–ø—Ä–µ—Å—Ç—É–ø–Ω–æ—Å—Ç—å", "phishing"],
}

# ==============================
# 3. –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ==============================

def contains_word(text: str, word: str) -> bool:
    """–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤–∞ —Å –≥—Ä–∞–Ω–∏—Ü–∞–º–∏"""
    return bool(re.search(rf'\b{re.escape(word)}\b', text, re.IGNORECASE))

def count_toxic_words(text: str, keywords: list) -> int:
    """–°—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Å–ª–æ–≤ (–¥–ª—è –æ—Ü–µ–Ω–∫–∏ —É—Ä–æ–≤–Ω—è)"""
    return sum(1 for word in keywords if contains_word(text, word))

# ==============================
# 4. –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ==============================

def detect_jailbreak(prompt: str) -> dict:
    # üîç –≠—Ç–∞–ø 1: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
    cleaned = clean_text(prompt)
    
    # üî• –≠—Ç–∞–ø 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ jailbreak-–ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    for pattern in JAILBREAK_PATTERNS:
        if re.search(pattern, cleaned, re.IGNORECASE):
            return {
                "flagged": True,
                "reason": "jailbreak_attempt",
                "risk_score": 0.95,
                "suggested_rewrite": "–Ø –Ω–µ –º–æ–≥—É –≤—ã–ø–æ–ª–Ω–∏—Ç—å —ç—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å. –î–∞–≤–∞–π—Ç–µ –æ–±—Å—É–¥–∏–º —á—Ç–æ-—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏ –ø–æ–ª–µ–∑–Ω–æ–µ."
            }
    
    # ‚ò†Ô∏è –≠—Ç–∞–ø 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫—Å–∏—á–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    toxic_count = count_toxic_words(cleaned, TOXIC_KEYWORDS)
    if toxic_count >= 1:
        risk = min(0.7 + toxic_count * 0.1, 0.9)  # —á–µ–º –±–æ–ª—å—à–µ —Å–ª–æ–≤ ‚Äî —Ç–µ–º –≤—ã—à–µ —Ä–∏—Å–∫
        return {
            "flagged": True,
            "reason": "toxic_content",
            "risk_score": round(risk, 2),
            "suggested_rewrite": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—â–∞–π—Ç–µ—Å—å —É–≤–∞–∂–∏—Ç–µ–ª—å–Ω–æ. –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?"
        }
    
    # üö´ –≠—Ç–∞–ø 4: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã—Ö —Ç–µ–º
    for category, words in BANNED_TOPICS.items():
        for word in words:
            if contains_word(cleaned, word):
                risk = 0.85 if category in ["violence", "drugs", "self_harm"] else 0.75
                return {
                    "flagged": True,
                    "reason": f"harmful_content_{category}",
                    "risk_score": risk,
                    "suggested_rewrite": "–≠—Ç–∞ —Ç–µ–º–∞ –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ —Ä–∞–º–∫–∏ –º–æ–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π. –ß–µ–º –µ—â—ë —è –º–æ–≥—É –ø–æ–º–æ—á—å?"
                }
    
    # ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–æ
    return {
        "flagged": False,
        "reason": "safe",
        "risk_score": 0.0,
        "suggested_rewrite": prompt
    }
